{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiHV6ip2f5id"
      },
      "source": [
        "# LLM Reference Architecture using Redis & Google Cloud Platform\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/RedisVentures/redis-google-llms/blob/main/BigQuery_Palm_Redis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook serves as a getting started guide for working with LLMs on Google Cloud Platform with Redis Enterprise.\n",
        "\n",
        "## Intro\n",
        "Google's Vertex AI has expanded its capabilities by introducing [Generative AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview). This advanced technology comes with a specialized [in-console studio experience](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/quickstart), a [dedicated API](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/api-quickstart) and [Python SDK](https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk) designed for deploying and managing instances of Google's powerful Gemini language models.\n",
        "\n",
        "Redis Enterprise offers robust vector database features, with an efficient API for vector index creation, management, distance metric selection, similarity search, and hybrid filtering. When coupled with its versatile data structures - including lists, hashes, JSON, and sets - Redis Enterprise shines as the optimal solution for crafting high-quality Large Language Model (LLM)-based applications. It embodies a streamlined architecture and exceptional performance, making it an instrumental tool for production environments.\n",
        "\n",
        "Below we will work through several design patterns with Vertex AI LLMs and Redis Enterprise that will ensure optimal production performance.\n",
        "\n",
        "___\n",
        "## Contents\n",
        "- Setup\n",
        "    1. Prerequisites\n",
        "    2. Obtain Dataset\n",
        "    3. Generate Embeddings\n",
        "    4. Create Index\n",
        "    5. Query\n",
        "- Building a RAG Pipeline from scratch\n",
        "- Demo\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK2rWODkw-kX"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37rbBPKdL09o"
      },
      "source": [
        "## 1. Prerequisites\n",
        "Before we begin, we must install some required libraries, authenticate with Google, create a Redis database, and initialize other required components.\n",
        "\n",
        "### Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc-IxYu3wnQm"
      },
      "outputs": [],
      "source": [
        "!pip install -U git+https://github.com/RedisVentures/redisvl.git google-cloud-aiplatform langchain unstructured[pdf] gradio\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr_IviwqFS7K"
      },
      "source": [
        "### Using Free Redis Cloud account on GCP\n",
        "You can also use Forever Free instance of Redis Cloud. To activate it:\n",
        "- Head to https://redis.com/try-free/\n",
        "- Register (using gmail-based registration is the easiest)\n",
        "- Create New Subscription\n",
        "- Use the following options:\n",
        "    - Fixed plan, Google Cloud\n",
        "    - New 30Mb Free database\n",
        "- Create new RedisStack DB\n",
        "\n",
        "If you are registering at Redis Cloud for the first time - the last few steps would be performed for you by default. Capture the host, port and default password of the new database. You can use these instead of default `localhost` based in the following code block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5kx9ePDwwp6"
      },
      "source": [
        "^^^ If prompted press the Restart button to restart the kernel. ^^^\n",
        "\n",
        "### Install Redis locally (optional)\n",
        "If you have a Redis db running elsewhere with [Redis Stack](https://redis.io/docs/about/about-stack/) installed, you don't need to run it on this machine. You can skip to the \"Connect to Redis server\" step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs4KZURX4XpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5223285-6e72-4b3a-f763-fdb9080db951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb jammy main\n",
            "Starting redis-stack-server, database path /var/lib/redis-stack\n"
          ]
        }
      ],
      "source": [
        "%%sh\n",
        "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
        "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
        "sudo apt-get update  > /dev/null 2>&1\n",
        "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
        "redis-stack-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvDp8WNz4XpU"
      },
      "source": [
        "### Connect to Redis server\n",
        "Replace the connection params below with your own if you are connecting to an external Redis instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duCyNgfZ4XpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7333f39-9575-4899-9c77-647287c9fd1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import redis\n",
        "\n",
        "# Redis connection params\n",
        "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\") #\"redis-12110.c82.us-east-1-2.ec2.cloud.redislabs.com\"\n",
        "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")      #12110\n",
        "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")  #\"pobhBJP7Psicp2gV0iqa2ZOc1WdXXXXX\"\n",
        "\n",
        "# Create Redis client\n",
        "redis_client = redis.Redis(\n",
        "  host=REDIS_HOST,\n",
        "  port=REDIS_PORT,\n",
        "  password=REDIS_PASSWORD\n",
        ")\n",
        "\n",
        "# Test connection\n",
        "redis_client.ping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rrz76w96dF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7227c0-c340-47e4-fca3-a6624d0d69eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Clear Redis database (optional)\n",
        "redis_client.flushdb()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpjxW-kou-FY"
      },
      "source": [
        "### Authenticate to Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeTJb51SKs_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45cbcbb-2981-4356-fe9e-55b10a0ed370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yil6twAvIuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095ee197-3951-4d09-de67-bcfc577f44c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ID:··········\n",
            "REGION:us-central1\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# input your GCP project ID and region for Vertex AI\n",
        "PROJECT_ID = getpass(\"PROJECT_ID:\") #'central-beach-194106'\n",
        "REGION = input(\"REGION:\") #'us-central1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vDGqjHmVgjB"
      },
      "source": [
        "## 2. Obtain dataset\n",
        "\n",
        "Below pull the dataset from ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pxshas3XpgdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6014776c-4128-4bad-b0a1-053327f04b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘resources’: File exists\n",
            "--2024-04-05 20:04:11--  https://www.irs.gov/pub/irs-pdf/p5718.pdf\n",
            "Resolving www.irs.gov (www.irs.gov)... 23.213.23.225, 2600:1409:12:2b9::f50, 2600:1409:12:2a4::f50\n",
            "Connecting to www.irs.gov (www.irs.gov)|23.213.23.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8749823 (8.3M) [application/pdf]\n",
            "Saving to: ‘resources/p5718.pdf.1’\n",
            "\n",
            "p5718.pdf.1         100%[===================>]   8.34M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-04-05 20:04:12 (68.8 MB/s) - ‘resources/p5718.pdf.1’ saved [8749823/8749823]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Procure a dataset - downloading a publication from IRS\n",
        "!mkdir resources\n",
        "!wget https://www.irs.gov/pub/irs-pdf/p5718.pdf -P resources/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kh0ObD4xZtK"
      },
      "source": [
        "### Create text embeddings with Vertex AI embedding model\n",
        "Use the [Vertex AI API for text embeddings](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings), developed by Google.\n",
        "\n",
        "> Text embeddings are a dense vector representation of a piece of content such that, if two pieces of content are semantically similar, their respective embeddings are located near each other in the embedding vector space. This representation can be used to solve common NLP tasks, such as:\n",
        "> - **Semantic search**: Search text ranked by semantic similarity.\n",
        "> - **Recommendation**: Return items with text attributes similar to the given text.\n",
        "> - **Classification**: Return the class of items whose text attributes are similar to the given text.\n",
        "> - **Clustering**: Cluster items whose text attributes are similar to the given text.\n",
        "> - **Outlier Detection**: Return items where text attributes are least related to the given text.\n",
        "\n",
        "The Vertex AI text-embeddings API lets you create a text embedding using Generative AI on Vertex AI. The `textembedding-gecko` model accepts a maximum of 3,072 input tokens (i.e. words) and outputs 768-dimensional vector embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3o_9ehYuEpA"
      },
      "source": [
        "### Set up embeddings\n",
        "We define a helper function to create embeddings from a list of texts convert them to a byte string for efficient storage in Redis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrpKY4W5yb0M"
      },
      "outputs": [],
      "source": [
        "from redisvl.utils.vectorize import VertexAITextVectorizer\n",
        "\n",
        "vectorizer = VertexAITextVectorizer(\n",
        "    model = \"textembedding-gecko@003\",\n",
        "    api_config = {\"project_id\": PROJECT_ID, \"location\": REGION}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peFHIY351eDc"
      },
      "source": [
        "## 3. Generate Embeddings\n",
        "The next step is to create chunks of the pdf and then embed each chunk as a vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzkRiknVXOtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14102f38-d0ce-4baf-fe16-ac060c6fa117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done preprocessing. Created 44 chunks of the original pdf resources/p5718.pdf\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "doc = \"resources/p5718.pdf\"\n",
        "\n",
        "# set up the file loader/extractor and text splitter to create chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2500, chunk_overlap=0\n",
        ")\n",
        "loader = UnstructuredFileLoader(\n",
        "    doc, mode=\"single\", strategy=\"fast\"\n",
        ")\n",
        "\n",
        "# extract, load, and make chunks\n",
        "chunks = loader.load_and_split(text_splitter)\n",
        "\n",
        "print(\"Done preprocessing. Created\", len(chunks), \"chunks of the original pdf\", doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OETsrYvfuzmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398c7a3e-8777-443c-991a-50d9af3ba99f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Embed each chunk content\n",
        "embeddings = vectorizer.embed_many([chunk.page_content for chunk in chunks], as_buffer=True)\n",
        "\n",
        "# Check to make sure we've created enough embeddings, 1 per document chunk\n",
        "len(embeddings) == len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGVt7-DNr80e"
      },
      "source": [
        "## 4. Create Index\n",
        "\n",
        "Now that we have created embeddings that represent the text in our dataset, we will create an index that enables efficient search over the embeddings.\n",
        "\n",
        "**Why do we need to enable search???**\n",
        "Using Redis for vector search allows us to retrieve chunks of text data that are **similar** or **relevant** to an input question or query. This will be extremely helpful for our sample generative ai / LLM application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mNa5LNn4XpX"
      },
      "outputs": [],
      "source": [
        "from redisvl.schema import IndexSchema\n",
        "from redisvl.index import SearchIndex\n",
        "\n",
        "\n",
        "index_name = \"redisvl\"\n",
        "\n",
        "schema = IndexSchema.from_dict({\n",
        "  \"index\": {\n",
        "    \"name\": index_name,\n",
        "    \"prefix\": \"chunk\"\n",
        "  },\n",
        "  \"fields\": [\n",
        "    {\n",
        "        \"name\": \"chunk_id\",\n",
        "        \"type\": \"tag\",\n",
        "        \"attrs\": {\n",
        "            \"sortable\": True\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"content\",\n",
        "        \"type\": \"text\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"text_embedding\",\n",
        "        \"type\": \"vector\",\n",
        "        \"attrs\": {\n",
        "            \"dims\": vectorizer.dims,\n",
        "            \"distance_metric\": \"cosine\",\n",
        "            \"algorithm\": \"flat\",\n",
        "            \"datatype\": \"float32\"\n",
        "        }\n",
        "    }\n",
        "  ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNjHD3D94_Sc"
      },
      "outputs": [],
      "source": [
        "# Create an index from schema and the client\n",
        "index = SearchIndex(schema, redis_client)\n",
        "index.create(overwrite=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOzL5qB-uzrE"
      },
      "outputs": [],
      "source": [
        "# Load expects an iterable of dictionaries\n",
        "data = [\n",
        "    {\n",
        "        'chunk_id': f'{i}',\n",
        "        'content': chunk.page_content,\n",
        "        'text_embedding': embeddings[i]\n",
        "    } for i, chunk in enumerate(chunks)\n",
        "]\n",
        "\n",
        "# RedisVL handles batching automatically\n",
        "keys = index.load(data, id_field=\"chunk_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6CmHY3-6wB1"
      },
      "source": [
        "## 5. Query\n",
        "Now we can use RedisVL to perform a variety of vector search operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9HKH8kO5T3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04c76337-81de-46fc-a347-c1ca748a52e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*=>[KNN 3 @text_embedding $vector AS vector_distance] RETURN 3 chunk_id content vector_distance SORTBY vector_distance ASC DIALECT 2 LIMIT 0 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from redisvl.query import VectorQuery\n",
        "\n",
        "query = \"What is TCC?\"\n",
        "\n",
        "query_embedding = vectorizer.embed(query)\n",
        "\n",
        "vector_query = VectorQuery(\n",
        "    vector=query_embedding,\n",
        "    vector_field_name=\"text_embedding\",\n",
        "    num_results=3,\n",
        "    return_fields=[\"chunk_id\", \"content\"],\n",
        "    return_score=True\n",
        ")\n",
        "\n",
        "# show the raw redis query\n",
        "str(vector_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_-AlXmE5dUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe06d6b-9d21-49d0-f9cc-531dab95fd50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'chunk:11',\n",
              "  'vector_distance': '0.343767404556',\n",
              "  'chunk_id': '11',\n",
              "  'content': 'When your IRIS Application for TCC is approved and completed, a five-character alphanu- meric TCC that begins with the letter ‘D’ will be assigned to your business. An approval letter will be sent via United States Postal Service (USPS) to the address listed on the application, informing you of your TCC. You can also sign into your IRIS Application for TCC to view your TCCs on the Application Summary page.\\n\\n13\\n\\nPublication 5718\\n\\nIf your application is in Completed status for more than 45 days and your TCC has not been assigned, contact the Help Desk.\\n\\n1.3.7 Revise Current TCC Information\\n\\nAs changes occur, you must update and maintain your IRIS TCC Application. Some changes will require all ROs or Authorized Delegates (ADs) on the application to re-sign the Appli- cation Submission page. Below are examples of when an application would need to be re-signed (this list is not all inclusive):\\n\\nFirm’s DBA Name change\\n\\nRole changes or additions\\n\\nAdd, delete or change RO and/or AD\\n\\nNote: Changes submitted on an IRIS TCC Application do not change the address of IRS tax records just as a change of address to IRS tax records does not automatically update infor- mation on an IRIS TCC Application.\\n\\nChanges that require a firm to acquire a new Employer Identification Number (EIN) require a new IRIS TCC Application. Firms that change their form of organization, such as from a sole proprietorship to a corporation, generally require the firm to acquire a new EIN.\\n\\n1.3.8 Deleted TCCs\\n\\nYour TCCs will remain valid if you transmit information returns or extensions of time to file. If you don’t use your TCC for three consecutive years, your TCC will be deleted. Once your TCC is deleted it cannot be reactivated. You’ll need to submit a new IRIS Application for TCC.\\n\\n1.4 Transmitter and Issuer TCCs\\n\\nDepending on the roles selected on the application, one or more TCCs will be assigned. Each TCC will have an indicator of Test “T” or Production “P” and status of Active, Inactive, or Dropped. Transmitters and Issuers are issued a TCC in Test “T” status until required Communication Testing is conducted in the ATS environment and passed. Once Commu- nication Testing is passed, the Transmitter should contact the Help Desk to request to be moved to Production “P” status. For more information about Communication Testing for Transmitters, refer to Publication 5719, Information Returns Intake System (IRIS) Test Package for Information Returns.\\n\\n1.5 Software Developer TCCs'},\n",
              " {'id': 'chunk:9',\n",
              "  'vector_distance': '0.344546079636',\n",
              "  'chunk_id': '9',\n",
              "  'content': 'Select the role of Transmitter on your application. Note: The TCC for a Transmitter can be used to transmit your own returns and others. You may not use an Issuer TCC to transmit information returns for others.\\n\\n11\\n\\nPublication 5718\\n\\n1.3.3 Third-Party Transmitters\\n\\nIf you do not have an in-house programmer familiar with XML or do not wish to purchase A2A software that is certified to support the information returns that you plan to file, you can file through a Third-Party Transmitter or use the online Taxpayer Portal. Visit www.irs.gov/ iris for additional information.\\n\\nOnly those persons listed as an Authorized User on the IRIS Application for TCC qualify to receive information about a Receipt ID associated with a TCC listed on that application.\\n\\nIf your Third-Party Transmitter needs technical assistance regarding a Receipt ID associated with records that were submitted on behalf of your organization, they should contact the Help Desk.\\n\\nWhen filing through a Third-Party Transmitter obtain the following for each submission filed on your behalf:\\n\\nA copy of all electronic records within each submission, along with the Receipt ID for the transmission in which they were filed.\\n\\nThe transmission Acknowledgement that includes the Status that is returned when processing is complete (Accepted, Accepted With Errors, Partially Accepted, Rejected) and a detailed list of errors, if any.\\n\\nNote: The items cited above are critical to your ability to make corrections should your Third- party Transmitter go out of business or be otherwise unavailable to file corrections on your behalf.\\n\\n1.3.4 Things you need to know before completing the IRIS\\n\\nA responsible official (RO) initiates and submits the IRIS Application for TCC electronically. Each RO must sign the terms of agreement using their five-digit PIN they created when they initially accessed the system. An application will receive a tracking number after saving it. Completing the application in a single session isn’t a requirement.\\n\\nThe following information is necessary to complete each application:\\n\\nFirm’s business structure\\n\\nFirm’s (EIN) (the system doesn’t allow firms to use a Social Security Number (SSN) or Individual Taxpayer Identification Number (ITIN)\\n\\nFirm’s legal business name and business type\\n\\nFirm’s doing business as name when it’s different from the legal business name\\n\\nBusiness phone (phone country code and phone number)\\n\\nBusiness address (this must be a physical location, not a post office box)'},\n",
              " {'id': 'chunk:8',\n",
              "  'vector_distance': '0.345553815365',\n",
              "  'chunk_id': '8',\n",
              "  'content': 'Software Developer: An organization writing either origination or transmission software according to IRS specifications.\\n\\nTransmitter: A Third-Party sending the electronic information returns data directly to IRS on behalf of any business.\\n\\n\\n\\n(Note: If you are transmitting returns for your own company, in addition to transmitting returns on behalf of another business, you do not need both the Transmitter and Issuer role. You can file all returns as a Transmitter.)\\n\\n\\n\\nIssuer: A business filing their own information returns regardless of whether they are required to file electronically or volunteer to file electronically\\n\\n10\\n\\nPublication 5718\\n\\nThese roles are not mutually exclusive, for example, a firm or organization may be both a Transmitter and a Software Developer. Each role will receive its own TCC to be used based on the activity being performed. For example, Software Developers performing Testing will use the Software Developer TCC. Do not use the Software Developer TCC to transmit Production files.\\n\\nNote: If an organization requires more than one TCC for any given role, a Responsible Official listed on the application should request an additional TCC by clicking on the ‘Request’ option under ‘Request Additional TCC’ on the Application Summary Page.\\n\\nThe table below provides examples of who should apply for a TCC.\\n\\nTable 1-1: TCC Roles\\n\\nWhat roles should I select on my IRIS Application for Transmitter Control Code?\\n\\nSoftware Purchased or Developed?\\n\\nIf…\\n\\nAnd\\n\\nThen\\n\\nDeveloped\\n\\nI am a commercial Software Developer developing software and selling software,\\n\\nI will transmit information for others.\\n\\nSelect both the Software Developer role and the Transmitter role on your application.\\n\\nDeveloped\\n\\nI am developing my own software package, or contracted with someone to develop a unique package for my sole use,\\n\\nI will perform the software testing with IRS and transmit my own information returns.\\n\\nSelect the roles of Software Developer and Issuer on your application.\\n\\nPurchased\\n\\nI am purchasing a software package,\\n\\nI will transmit my own information returns.\\n\\nSelect the role of Issuer on your application. Note: You may not use an Issuer TCC to transmit information returns for others.\\n\\nPurchased\\n\\nI am purchasing a software package,\\n\\nI will transmit my own information returns and transmit for others.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# execute the query with RedisVL\n",
        "index.query(vector_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vT4bTYB5h74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6016ace0-cfc5-4871-d977-302b60cf7269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 0.343767404556\n",
            "9 0.344546079636\n",
            "8 0.345553815365\n"
          ]
        }
      ],
      "source": [
        "# paginate through results\n",
        "for result in index.paginate(vector_query, page_size=1):\n",
        "    print(result[0][\"chunk_id\"], result[0][\"vector_distance\"], flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9MjgGiCLLqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5655d1e5-b525-425e-d470-dd4ee07a08ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@content:(Social Security)=>[KNN 3 @text_embedding $vector AS vector_distance] RETURN 3 chunk_id content vector_distance SORTBY vector_distance ASC DIALECT 2 LIMIT 0 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from redisvl.query.filter import Text\n",
        "\n",
        "query = \"What is TCC?\"\n",
        "\n",
        "query_embedding = vectorizer.embed(query)\n",
        "\n",
        "text_filter = Text(\"content\") % \"Social Security\"\n",
        "\n",
        "vector_query = VectorQuery(\n",
        "    vector=query_embedding,\n",
        "    vector_field_name=\"text_embedding\",\n",
        "    num_results=3,\n",
        "    return_fields=[\"chunk_id\", \"content\"],\n",
        "    return_score=True,\n",
        "    filter_expression=text_filter\n",
        ")\n",
        "\n",
        "# show the raw redis query\n",
        "str(vector_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXci2AeGUMtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884ee3a0-2e0d-4ec0-e54c-508fbb8b21d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'chunk:9',\n",
              "  'vector_distance': '0.344546079636',\n",
              "  'chunk_id': '9',\n",
              "  'content': 'Select the role of Transmitter on your application. Note: The TCC for a Transmitter can be used to transmit your own returns and others. You may not use an Issuer TCC to transmit information returns for others.\\n\\n11\\n\\nPublication 5718\\n\\n1.3.3 Third-Party Transmitters\\n\\nIf you do not have an in-house programmer familiar with XML or do not wish to purchase A2A software that is certified to support the information returns that you plan to file, you can file through a Third-Party Transmitter or use the online Taxpayer Portal. Visit www.irs.gov/ iris for additional information.\\n\\nOnly those persons listed as an Authorized User on the IRIS Application for TCC qualify to receive information about a Receipt ID associated with a TCC listed on that application.\\n\\nIf your Third-Party Transmitter needs technical assistance regarding a Receipt ID associated with records that were submitted on behalf of your organization, they should contact the Help Desk.\\n\\nWhen filing through a Third-Party Transmitter obtain the following for each submission filed on your behalf:\\n\\nA copy of all electronic records within each submission, along with the Receipt ID for the transmission in which they were filed.\\n\\nThe transmission Acknowledgement that includes the Status that is returned when processing is complete (Accepted, Accepted With Errors, Partially Accepted, Rejected) and a detailed list of errors, if any.\\n\\nNote: The items cited above are critical to your ability to make corrections should your Third- party Transmitter go out of business or be otherwise unavailable to file corrections on your behalf.\\n\\n1.3.4 Things you need to know before completing the IRIS\\n\\nA responsible official (RO) initiates and submits the IRIS Application for TCC electronically. Each RO must sign the terms of agreement using their five-digit PIN they created when they initially accessed the system. An application will receive a tracking number after saving it. Completing the application in a single session isn’t a requirement.\\n\\nThe following information is necessary to complete each application:\\n\\nFirm’s business structure\\n\\nFirm’s (EIN) (the system doesn’t allow firms to use a Social Security Number (SSN) or Individual Taxpayer Identification Number (ITIN)\\n\\nFirm’s legal business name and business type\\n\\nFirm’s doing business as name when it’s different from the legal business name\\n\\nBusiness phone (phone country code and phone number)\\n\\nBusiness address (this must be a physical location, not a post office box)'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# execute the query with RedisVL\n",
        "index.query(vector_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82-AbKHxItif"
      },
      "source": [
        "# Building a RAG Pipeline from Scratch\n",
        "We're going to build a complete RAG pipeline from scratch incorporating the following components:\n",
        "\n",
        "- Standard retrieval and chat completion\n",
        "- Dense content representation to improve accuracy\n",
        "- Query re-writing to improve accuracy\n",
        "- Semantic caching to improve performance\n",
        "- Conversational session history to improve personalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6BsbxUG7kVc"
      },
      "outputs": [],
      "source": [
        "#@title Setup RedisVL *AsyncSearchIndex*\n",
        "\n",
        "from redis.asyncio import Redis\n",
        "from redisvl.index import AsyncSearchIndex\n",
        "\n",
        "# Create Redis client\n",
        "redis_client = Redis(\n",
        "    host=REDIS_HOST,\n",
        "    port=REDIS_PORT,\n",
        "    password=REDIS_PASSWORD\n",
        ")\n",
        "\n",
        "index = AsyncSearchIndex(index.schema, redis_client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSbXjA896Ami"
      },
      "outputs": [],
      "source": [
        "#@title Setup VertexAI Generative Model with Safety Settings\n",
        "from vertexai.generative_models import GenerativeModel, Part, HarmCategory, HarmBlockThreshold\n",
        "\n",
        "\n",
        "model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
        "\n",
        "# Define safety settings\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "}\n",
        "\n",
        "# Define generation config\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 2048,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 1\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ep2DbPB_Rmu"
      },
      "source": [
        "### Baseline Retrieval Augmented Generation\n",
        "\n",
        "Below we build a simple RAG pipeline with three helper methods:\n",
        "\n",
        "\n",
        "*   `answer_question` -- full RAG operation\n",
        "    * `retrieve_context` -- search Redis for relevant sources\n",
        "    * `promptify`  -- combine system instructions, user question, and sources\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmma7Cjd7kZ9"
      },
      "outputs": [],
      "source": [
        "async def answer_question(index: AsyncSearchIndex, query: str):\n",
        "    \"\"\"Answer the user's question\"\"\"\n",
        "\n",
        "    SYSTEM_PROMPT = \"\"\"You are a helpful tax analyst assistant that has access\n",
        "    to publications from the IRS\n",
        "    \"\"\"\n",
        "\n",
        "    query_vector = vectorizer.embed(query)\n",
        "\n",
        "    # Fetch context from Redis using vector search\n",
        "    context = await retrieve_context(index, query_vector)\n",
        "\n",
        "    prompt = f'''\n",
        "    System: {SYSTEM_PROMPT}\n",
        "    User: {promptify(query, context)}\n",
        "    '''\n",
        "\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False\n",
        "    )\n",
        "    # Response provided by LLM\n",
        "    if(responses.candidates[0].finish_reason.value == 1):\n",
        "        return(responses.candidates[0].content.parts[0].text)\n",
        "    else:\n",
        "        return(f\"Content has been blocked for {responses.candidates[0].finish_reason.name} reasons.\")\n",
        "\n",
        "\n",
        "async def retrieve_context(index: AsyncSearchIndex, query_vector) -> str:\n",
        "    \"\"\"Fetch the relevant context from Redis using vector search\"\"\"\n",
        "    results = await index.query(\n",
        "        VectorQuery(\n",
        "            vector=query_vector,\n",
        "            vector_field_name=\"text_embedding\",\n",
        "            return_fields=[\"content\"],\n",
        "            num_results=3\n",
        "        )\n",
        "    )\n",
        "    content = \"\\n\".join([result[\"content\"] for result in results])\n",
        "    return content\n",
        "\n",
        "\n",
        "def promptify(query: str, context: str) -> str:\n",
        "    return f'''Use the provided context below derived from public documenation to answer the user's question. If you can't answer the user's\n",
        "    question, based on the context; do not guess. Do your best finding the answer in the context, but if there is no context at all,\n",
        "    respond with \"I don't know\".\n",
        "\n",
        "    User question:\n",
        "\n",
        "    {query}\n",
        "\n",
        "    Helpful context:\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Answer:\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIaYNgNxA4D1"
      },
      "outputs": [],
      "source": [
        "# Generate a list of questions\n",
        "questions = [\n",
        "    \"What is TCC?\",\n",
        "    \"Who should apply for an IRIS TCC?\",\n",
        "    \"What is a JWK?\",\n",
        "    \"Should I buy a yacht??\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy7rh-stIIii"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "results = await asyncio.gather(*[\n",
        "    answer_question(index, question) for question in questions\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_HZnaBo6ylG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d12ba416-e408-4f4b-e8e2-8e57474adc5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is TCC?: \n",
            "TCC stands for Transmitter Control Code.\n",
            "\n",
            "\n",
            "Who should apply for an IRIS TCC?: \n",
            "If you are transmitting information returns to the IRS or if you are developing software to file information returns electronically, you must apply for one or more TCCs using the IRIS Application for TCC available online.\n",
            "\n",
            "\n",
            "What is a JWK?: \n",
            "A JSON Web Key (JWK) is a cryptographic key that is used for e-Services API authentication. It contains a public key that validates the API consumer application. JWKs will have the following criteria:\n",
            "\n",
            "JWKs should contain a public key using RSA algorithm. RSA provides a key ID for key matching purposes.\n",
            "\n",
            "Should contain X.509 certificate using both “x5t” (X.509 SHA-1 Thumbprint) and “x5c” (X.509 certificate Chain) parameters.\n",
            "\n",
            "You are not allowed to use self-signed certificates.\n",
            "\n",
            "You can use the same public certificate as used for other IRS programs such as MeF or AIR.\n",
            "\n",
            "For more information on Digital Certificates visit Digital Certificates | Internal Revenue Service\n",
            "\n",
            "The set of JWK attributes need to be pasted into the JSON Web Key (JWK) section of your application following these guidelines:\n",
            "\n",
            "Must be in the order listed below\n",
            "\n",
            "Remove any attribute names not in the list below\n",
            "\n",
            "Paste the full JWK including all the beginning ‘{‘ and ending curly braces ‘}’ to avoid errors\n",
            "\n",
            "A text editing tool may be useful when rearranging and/or removing attributes not listed below\n",
            "\n",
            "Please refer to ‘Figure 1-1’ for a JWK example\n",
            "\n",
            "The attributes expected in JWK are:\n",
            "\n",
            "{\n",
            "\n",
            "“kty”: Key Type (must be RSA)\n",
            "\n",
            "{\n",
            "\n",
            "“kid”: Key ID\n",
            "\n",
            "{\n",
            "\n",
            "“use”: “sig” Public Key Use\n",
            "\n",
            "{\n",
            "\n",
            "“n”: the modulus\n",
            "\n",
            "{\n",
            "\n",
            "“e”: “AQAB” the public exponent\n",
            "\n",
            "{\n",
            "\n",
            "“x5c”: X. 509 Certificate Chain\n",
            "\n",
            "{\n",
            "\n",
            "“x5t”: X.509 Certificate SHA-1 Thumbprint\n",
            "Note: if any of the above attributes are missing from the JWK, the JWK will be invalid. Please refer to Figure 1-1, which contains an example of an RSA key represented as JWKs. Paste the full JWK including the beginning ‘{‘ and ending curly braces ‘}’ to avoid errors. If there are no errors, you will see the Submission Complete page and you will be able to view the issued Client ID.\n",
            "\n",
            "\n",
            "Should I buy a yacht??: \n",
            "I don't know\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for question, result in zip(questions,results):\n",
        "  print(question+\": \\n\"+result+\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN3Ok2zJMhdt"
      },
      "source": [
        "# Improve performance and cut costs with LLM Semantic Caching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzX8lQ35Mpee"
      },
      "outputs": [],
      "source": [
        "from redis import Redis\n",
        "from redisvl.extensions.llmcache import SemanticCache\n",
        "\n",
        "# Create Redis client\n",
        "redis_client = Redis(\n",
        "  host=REDIS_HOST,\n",
        "  port=REDIS_PORT,\n",
        "  password=REDIS_PASSWORD\n",
        ")\n",
        "\n",
        "# Create the Semantic Cache\n",
        "llmcache = SemanticCache(\n",
        "    name=\"llmcache\",\n",
        "    vectorizer=vectorizer,\n",
        "    redis_client=redis_client,\n",
        "    ttl=120,\n",
        "    distance_threshold=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaovoOKbMrSG"
      },
      "outputs": [],
      "source": [
        "from functools import wraps\n",
        "\n",
        "\n",
        "# Create an LLM caching decorator\n",
        "def cache(func):\n",
        "    @wraps(func)\n",
        "    async def wrapper(index, query_text, *args, **kwargs):\n",
        "        query_vector = llmcache._vectorizer.embed(query_text)\n",
        "\n",
        "        # Check the cache with the vector\n",
        "        if result := llmcache.check(vector=query_vector):\n",
        "            return result[0]['response']\n",
        "\n",
        "        response = await func(index, query_text, query_vector=query_vector)\n",
        "        llmcache.store(query_text, response, query_vector)\n",
        "        return response\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "@cache\n",
        "async def answer_question(index: AsyncSearchIndex, query: str, **kwargs):\n",
        "    \"\"\"Answer the user's question\"\"\"\n",
        "\n",
        "    SYSTEM_PROMPT = \"\"\"You are a helpful tax analyst assistant that has access\n",
        "    to publications from the IRS\n",
        "    \"\"\"\n",
        "\n",
        "    # Fetch context from Redis using vector search\n",
        "    context = await retrieve_context(index, kwargs[\"query_vector\"])\n",
        "\n",
        "    prompt = f'''\n",
        "    System: {SYSTEM_PROMPT}\n",
        "    User: {promptify(query, context)}\n",
        "    '''\n",
        "\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False\n",
        "    )\n",
        "    # Response provided by LLM\n",
        "    if(responses.candidates[0].finish_reason.value == 1):\n",
        "        return(responses.candidates[0].content.parts[0].text)\n",
        "    else:\n",
        "        return(f\"Content has been blocked for {responses.candidates[0].finish_reason.name} reasons.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4d6PJG01hcz"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAMpnoVIP7G1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae0cb12-6a8a-48ad-88ca-190090e6161a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0:00:01.661276\n"
          ]
        }
      ],
      "source": [
        "query = \"What is a JWK?\"\n",
        "\n",
        "startTime = datetime.now()\n",
        "await answer_question(index, query)\n",
        "print(f\"Total time: {datetime.now() - startTime}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aepPokugQBNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec8cee5-e7de-45f9-b575-7e616c6100cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0:00:00.110198\n"
          ]
        }
      ],
      "source": [
        "# Now try again with semantic caching enabled!\n",
        "query = \"What's a JWK?\"\n",
        "\n",
        "startTime = datetime.now()\n",
        "await answer_question(index, query)\n",
        "print(f\"Total time: {datetime.now() - startTime}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6jxgpzWA2Ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "84f1e6f2-6351-4ffb-ba30-fce49326ee7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20:06:14 httpx INFO   HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
            "20:06:15 httpx INFO   HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "20:06:16 httpx INFO   HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
            "20:06:16 httpx INFO   HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "20:06:16 httpx INFO   HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "20:06:16 httpx INFO   HTTP Request: POST https://api.gradio.app/gradio-initiated-analytics/ \"HTTP/1.1 200 OK\"\n",
            "20:06:17 httpx INFO   HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "20:06:17 httpx INFO   HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_linux_amd64 \"HTTP/1.1 200 OK\"\n",
            "Running on public URL: https://b3d851f6267d343e99.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "20:06:17 httpx INFO   HTTP Request: HEAD https://b3d851f6267d343e99.gradio.live \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b3d851f6267d343e99.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "async def respond(message, history):\n",
        "    print(message)\n",
        "    result = await answer_question(index, message)\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "gr.ChatInterface(respond).launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}